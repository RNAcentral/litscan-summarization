<!doctype html>
{% extends "base.html" %}
{% block title %}LitSumm Feedback{% endblock %}

{% block content %}
<div class="container-fluid text-wrap">
    <h1 class="text-center">LitSumm</h1>
    <p class="text-start">Please assess the quality of the RNA summaries generated by LitSumm.
        These summaries have been created by taking sentences from LitScan and passing them through chatGPT to create what should be helpful summaries that give you a general idea what the literature says about a given RNA.
    </p>
    <p><b>This site has to store some cookies in your browser.  If you don't consent to that, don't click the start button at the bottom.</b> The cookies keep track of which RNA IDs you have seen, and give you a unique ID so I can differentiate reviews when analysing the data. The ID is random and should be completely anonymous.
        If you want to reset the list of IDs you've seen, there's a button at the bottom of this page.</p>

    <h2>Instructions</h2>
    <h3>General instructions</h3>
    <p>We are aiming to get a score for each of the summaries in this evaluation set. You should score based on how coherent the summary is, how much important information it managed to capture from the context, and how well it follows our instructions (i.e. references, made up information etc)</p>
    <p>You should primarily score on the 1-5 scale provided. However we would also like to get some deeper information if possible. This is optional, but if you have time, please fill in the additional feedback section.
        This will help us to understand what went wrong with the summaries, and how we can improve them in the future.</p>
    <p>There is also a free text feedback space. Treat this like you are talking to the 'person' who wrote the summary.</p>
    <p><b>Do not spend time reading into the papers</b>, to see if there is missing important information. The summary can only be made from the information in the context, so assess it based on that.</p>
    <p>From the way the context is constructed, we somewhat expect the summary to jump topic a bit, but if it is excessive, score the summary lower.</p>
    <p>Do not penalise the summary if it contains unexplained abbreviations, unless the abbreviation is explained in the context.</p>
    <p>Do not penalise the summary for having references formatted a bit badly, e.g. [PMC...][PMC...].</p>
    <p>However, if a summary has totally mis-formatted references, e.g. [1] instead of a PMCID, score it badly.</p>
    <p>I'm reasonably confident that the ID selection has excluded false positives, but should you encounter one, give it a score of 1 and make sure the false positive box is checked in the additional feedback.</p>
    <p>Finally, if you have no opinion on a summary, just click next and another one will load for you.</p>
    <h3>Getting started</h3>
    <p>The first thing to do is enter your name in the box below and click submit. This will store a cookie 'user_name' on your browser which we will use to aggregate your ratings. You can use a pseudonym if you like, as long as you're consistent.</p>
    <br>
    <p>To start reviewing, click start below. Doing so will take you to a page where the RNA ID is at the top, followed by the context in a collapsible element, then the chatGPT generated summary. You should see something that looks like this:</p>
    <div class="text-center">
        <img src="{{url_for('static', filename='Screen1.png')}}" class="img-thumbnail" style="max-width: 50%">
    </div>
    <p>If the context is in your way, click the bar across the top with "Context" in to collapse it</p>
    <p>the primary feedback is the 1-5 scale below the summary. In this rating 1 is worst and 5 is best. When you click the submit button, your rating will be submitted to the dtabase. Note that there isn't currently a way to revise a rating, but you can submit two ratings for something if you change your mind.</p>
    <p>Clicking Previous or Next will take you in whichever direction without submitting your rating. Use this if you want to skip something.</p>
    <p>If you want to provide additional feedback, you can expand the section below the rating to look something like this:</p>
    <div class="text-center">
        <img src="{{url_for('static', filename='Screen2.png')}}" class="img-thumbnail" style="max-width: 50%">
    </div>
    <p>One thing to note here - if you <i>don't</i> check a box, it implies that aspect of the summary was fine. It is totally fine not to provide additional feedback if you think the summary is ok.</p>
    <p>As mentioned, treat the free feedback as if you were instructing the model. State what is wrong and give instructions to rectify it</p>

    <h3 class="text-center">Thank you!</h3>
</div>
<div class="'container-fluid text-center">
    <label for="user_name" class="form-label">Please enter a name or pseudonym to identify your reviews</label>
    <input type="text" class="form-control" id="user_name" name="user_name" rows="1"></input>
    <button type="button" class="btn btn-success" id="user_name_submit" onclick="set_user_name()">Submit</button>
</div>
<br><hr><br>
<div class="container-fluid text-center">
    <div class="btn-group" role="group" aria-label="Basic mixed styles example">
        <button type="button" type="submit" class="btn btn-danger" onclick="reset_seen_list()" >Reset seen ID list</button>
        <button type="button" type="submit" class="btn btn-success" onclick=window.location.href="{{url_for('present_single_summary')}}">Start</button>
    </div>
</div>

{% endblock %}
